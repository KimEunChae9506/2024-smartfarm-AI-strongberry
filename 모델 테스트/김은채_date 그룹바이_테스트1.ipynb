{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/6Kc8Ebkz1w+zKP7ksbgz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimEunChae9506/2024-smartfarm-AI-strongberry/blob/main/%EA%B9%80%EC%9D%80%EC%B1%84_date_%EA%B7%B8%EB%A3%B9%EB%B0%94%EC%9D%B4_%ED%85%8C%EC%8A%A4%ED%8A%B81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq_Y3XdhmGrm",
        "outputId": "6454a042-6652-45d1-c643-1a91c7ae2a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² 트레인 결정계수: 0.5212611432516948\n",
            "R² 결정계수: 0.7998009411637814\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 파일 읽기\n",
        "file_path = '/content/STRAWBERRY_PRODUCTION_ENV_20221209.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터의 첫 몇 행을 출력하여 구조를 확인합니다.\n",
        "#data.head()\n",
        "# 데이터의 기본 정보 확인\n",
        "#data.info()\n",
        "\n",
        "# 통계 정보 확인\n",
        "#data.describe()\n",
        "\n",
        "# 결측값 확인\n",
        "#data.isnull().sum()\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#원-핫 인코딩. ZONE_NM 이라는 문자열을 숫자값으로 인코딩해서 독립변수로 쓸 수 있게 함.\n",
        "data = pd.get_dummies(data, columns=['ZONE_NM'], drop_first=False)\n",
        "\n",
        "# STRG_DT 컬럼을 datetime(날짜) 형식으로 변환\n",
        "data['STRG_DT'] = pd.to_datetime(data['STRG_DT'])\n",
        "\n",
        "# STRG_DT 컬럼에서 날짜만 추출(시간 제외 월,일만 추출)하여 Date 라는 새로운 컬럼 추가\n",
        "data['Date'] = data['STRG_DT'].dt.date\n",
        "\n",
        "#data.fillna(0, inplace=True) //빈 값 0으로 채우기\n",
        "\n",
        "#빈 값 있는 행 제거\n",
        "data = data.dropna()\n",
        "\n",
        "# 'Date' 열을 기준으로 데이터 그룹화 및 나머지 열 평균값 계산하여 'data_mean'이라는 임의의 데이터셋에 저장\n",
        "data_mean = data.groupby('Date').mean()\n",
        "\n",
        "#Date 컬럼을 만들었으니 STRG_DT 제거.\n",
        "data_mean.drop(['STRG_DT'], axis=1, inplace=True)\n",
        "\n",
        "# 'Date' 열을 기준으로 데이터 그룹화 및 SHPMN_QTY(출하량) 열 합계(일별) 계산하여 'data_sum'이라는 임의의 데이터셋에 저장\n",
        "data_sum = data.groupby('Date')['SHPMN_QTY'].sum()\n",
        "\n",
        "#data_sum 에서 출하량 합계 컬럼을 만들었으니 data_mean 의 SHPMN_QTY 컬럼 제거.\n",
        "data_mean.drop(['SHPMN_QTY'], axis=1, inplace=True)\n",
        "\n",
        "# 'data_mean' 과 'data_sum'를 합쳐 'merge_df' 데이터프레임 생성\n",
        "merge_df = pd.concat([data_mean, data_sum], axis=1)\n",
        "\n",
        "\n",
        "# 특징 변수(X)와 목표 변수(y)를 설정합니다.\n",
        "# 여기서는 출하량(SHPMN_QTY)을 목표 변수로 설정합니다.\n",
        "X = merge_df.drop(columns=['SHPMN_QTY'])\n",
        "y = merge_df['SHPMN_QTY']\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 분리합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "mMscaler = MinMaxScaler()\n",
        "X_train_scaled = mMscaler.fit_transform(X_train)\n",
        "X_test_scaled = mMscaler.transform(X_test)\n",
        "\n",
        "# 랜덤포레스트 모델을 훈련시킵니다.\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트에 대한 예측을 수행합니다.\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 결정계수를 계산합니다.\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R² 트레인 결정계수: {train_r2}')\n",
        "print(f'R² 결정계수: {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 파일 읽기\n",
        "file_path = '/content/STRAWBERRY_PRODUCTION_ENV_20221209.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터의 첫 몇 행을 출력하여 구조를 확인합니다.\n",
        "#data.head()\n",
        "# 데이터의 기본 정보 확인\n",
        "#data.info()\n",
        "\n",
        "# 통계 정보 확인\n",
        "#data.describe()\n",
        "\n",
        "# 결측값 확인\n",
        "#data.isnull().sum()\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#원-핫 인코딩. ZONE_NM 이라는 문자열을 숫자값으로 인코딩해서 독립변수로 쓸 수 있게 함.\n",
        "data = pd.get_dummies(data, columns=['ZONE_NM'], drop_first=False)\n",
        "\n",
        "# STRG_DT 컬럼을 datetime(날짜) 형식으로 변환\n",
        "data['STRG_DT'] = pd.to_datetime(data['STRG_DT'])\n",
        "\n",
        "# STRG_DT 컬럼에서 날짜만 추출(시간 제외 월,일만 추출)하여 Date 라는 새로운 컬럼 추가\n",
        "data['Date'] = data['STRG_DT'].dt.date\n",
        "\n",
        "#data.fillna(0, inplace=True) //빈 값 0으로 채우기\n",
        "\n",
        "#빈 값 있는 행 제거\n",
        "data = data.dropna()\n",
        "\n",
        "# 'Date' 열을 기준으로 데이터 그룹화 및 나머지 열 평균값 계산하여 'data_mean'이라는 임의의 데이터셋에 저장\n",
        "data_mean = data.groupby('Date').mean()\n",
        "\n",
        "#Date 컬럼을 만들었으니 STRG_DT 제거.\n",
        "data_mean.drop(['STRG_DT'], axis=1, inplace=True)\n",
        "\n",
        "# 'Date' 열을 기준으로 데이터 그룹화 및 SHPMN_QTY(출하량) 열 합계(일별) 계산하여 'data_sum'이라는 임의의 데이터셋에 저장\n",
        "data_sum = data.groupby('Date')['SHPMN_QTY'].sum()\n",
        "\n",
        "#data_sum 에서 출하량 합계 컬럼을 만들었으니 data_mean 의 SHPMN_QTY 컬럼 제거.\n",
        "data_mean.drop(['SHPMN_QTY'], axis=1, inplace=True)\n",
        "\n",
        "# 'data_mean' 과 'data_sum'를 합쳐 'merge_df' 데이터프레임 생성\n",
        "merge_df = pd.concat([data_mean, data_sum], axis=1)\n",
        "\n",
        "\n",
        "# 특징 변수(X)와 목표 변수(y)를 설정합니다.\n",
        "# 여기서는 출하량(SHPMN_QTY)을 목표 변수로 설정합니다.\n",
        "X = merge_df.drop(columns=['SHPMN_QTY'])\n",
        "y = merge_df['SHPMN_QTY']\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 분리합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "mMscaler = MinMaxScaler()\n",
        "X_train_scaled = mMscaler.fit_transform(X_train)\n",
        "X_test_scaled = mMscaler.transform(X_test)\n",
        "\n",
        "# XGBoost 모델을 훈련시킵니다.\n",
        "model = XGBRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트에 대한 예측을 수행합니다.\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 결정계수를 계산합니다.\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R² 트레인 결정계수: {train_r2}')\n",
        "print(f'R² 결정계수: {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsz8JG8rm0mK",
        "outputId": "aae8403a-4cf7-40ff-fec8-2138d8a2a9ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² 트레인 결정계수: 0.5970638152106866\n",
            "R² 결정계수: 0.7726016514754047\n"
          ]
        }
      ]
    }
  ]
}
