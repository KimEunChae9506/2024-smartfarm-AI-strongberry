{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR7GhI6Dcv84SZyvO/1Uo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimEunChae9506/2024-smartfarm-AI-strongberry/blob/main/%EA%B9%80%EC%9D%80%EC%B1%84_%EB%AA%A8%EB%8D%B8%EB%B3%84_%ED%85%8C%EC%8A%A4%ED%8A%B81(%EC%9B%90_%ED%95%AB_%EC%9D%B8%EC%BD%94%EB%94%A9).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델별 테스트1\n",
        "#서버 : 코랩 GPU\n",
        "#데이터 전처리 : 원-핫 인코딩\n",
        "#모델 4가지 테스트\n",
        "  #LinearRegression\n",
        "  #RandomForestRegressor\n",
        "  #SVR\n",
        "  #XGBRegressor\n",
        "\n",
        "#문제 : 정식일 이후 16주 동안 단위면적당 최소 에너지 비용(누적 난반용 도시가스 사용량)으로 최대 수확량을 예측 할 수 있는 환경/생육 모델을 구해라",
        "\n",
        "#결과\n",
        "# 1. RandomForestRegressor => 속도도 제일 빠르고, 결정계수도 제일 높음\n",
        "# 비고. SVR 은 30분이 넘어도 느려 포기."
      ],
      "metadata": {
        "id": "HlL6iHIdkQ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m0ATnN1WqzQ",
        "outputId": "6e5371c5-67e9-49a2-8321-6e92c1ff2f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training R2: 0.5354\n",
            "  Test R2: 0.5310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import chardet\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = 'dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#원-핫 인코딩\n",
        "data = pd.get_dummies(data, columns=['frmDist'], drop_first=False)\n",
        "\n",
        "# 데이터 전처리 (결측값 처리, 필요시 인코딩 등)\n",
        "data = data.dropna()\n",
        "\n",
        "# 독립 변수(X)와 종속 변수(y) 분리\n",
        "X = data.drop('outtrn_cumsum', axis=1)\n",
        "y = data['outtrn_cumsum']\n",
        "\n",
        "# 데이터 분할 (학습용 데이터와 테스트용 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 리스트\n",
        "model = LinearRegression()\n",
        "\n",
        "# 모델 성능 평가\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"  Training R2: {train_r2:.4f}\")\n",
        "print(f\"  Test R2: {test_r2:.4f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import chardet\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = 'dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#원-핫 인코딩\n",
        "data = pd.get_dummies(data, columns=['frmDist'], drop_first=False)\n",
        "\n",
        "# 데이터 전처리 (결측값 처리, 필요시 인코딩 등)\n",
        "data = data.dropna()\n",
        "\n",
        "# 독립 변수(X)와 종속 변수(y) 분리\n",
        "X = data.drop('outtrn_cumsum', axis=1)\n",
        "y = data['outtrn_cumsum']\n",
        "\n",
        "# 데이터 분할 (학습용 데이터와 테스트용 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 리스트\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 모델 성능 평가\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"  Training R2: {train_r2:.4f}\")\n",
        "print(f\"  Test R2: {test_r2:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSKhhT9dZK_m",
        "outputId": "2ad403c7-1423-4e8f-b754-8e267e9e6240"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training R2: 0.9984\n",
            "  Test R2: 0.9901\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import chardet\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = 'dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#원-핫 인코딩\n",
        "data = pd.get_dummies(data, columns=['frmDist'], drop_first=False)\n",
        "\n",
        "# 데이터 전처리 (결측값 처리, 필요시 인코딩 등)\n",
        "data = data.dropna()\n",
        "\n",
        "# 독립 변수(X)와 종속 변수(y) 분리\n",
        "X = data.drop('outtrn_cumsum', axis=1)\n",
        "y = data['outtrn_cumsum']\n",
        "\n",
        "# 데이터 분할 (학습용 데이터와 테스트용 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 리스트\n",
        "model = SVR()\n",
        "\n",
        "# 모델 성능 평가\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"  Training R2: {train_r2:.4f}\")\n",
        "print(f\"  Test R2: {test_r2:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "LMm8CP5GaXuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVR -> 너무 오래 걸려 포기"
      ],
      "metadata": {
        "id": "Ny7WdDD-iTj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import chardet\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = 'dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#원-핫 인코딩\n",
        "data = pd.get_dummies(data, columns=['frmDist'], drop_first=False)\n",
        "\n",
        "# 데이터 전처리 (결측값 처리, 필요시 인코딩 등)\n",
        "data = data.dropna()\n",
        "\n",
        "# 독립 변수(X)와 종속 변수(y) 분리\n",
        "X = data.drop('outtrn_cumsum', axis=1)\n",
        "y = data['outtrn_cumsum']\n",
        "\n",
        "# 데이터 분할 (학습용 데이터와 테스트용 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 리스트\n",
        "model = XGBRegressor(random_state=42)\n",
        "\n",
        "# 모델 성능 평가\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"  Training R2: {train_r2:.4f}\")\n",
        "print(f\"  Test R2: {test_r2:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sClfpVNbiVCU",
        "outputId": "b92d8e4c-88ce-4a1a-d96b-ed845c19f547"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training R2: 0.9548\n",
            "  Test R2: 0.9323\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
